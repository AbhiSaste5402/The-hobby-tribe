{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "retfd_oNJwAH",
        "outputId": "ff14ac26-1c05-42aa-e176-3b3812253f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "\n"
      ],
      "metadata": {
        "id": "NScDMphOJ8LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dataset_path='/content/drive/MyDrive/TRAINING'\n"
      ],
      "metadata": {
        "id": "coi52wkaMcHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "\n",
        "def extract_features(file_path):   #Defines a function named extract_features that takes a file_path as an argument.\n",
        "    y, sr = librosa.load(file_path)  #Loads an audio file located at file_path using 'librosa.load()'. It returns the audio waveform y and the sampling rate sr\n",
        "\n",
        "    #Extracts four different audio features using 'librosa.feature' functions. MFCCs (Mel-Frequency Cepstral Coefficients),\n",
        "     #Chroma features, Zero Crossing Rate, and Spectral Centroid are extracted from the audio waveform y.\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
        "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "    return mfccs, chroma, zero_crossing_rate, spectral_centroid   #Returns these extracted features from the function.\n",
        "\n",
        "def process_folder(folder_path):  #Defines a function process_folder that takes a folder_path as an argument.\n",
        "    features_list = []             # Initializes an empty list to store the extracted features and their associated labels.\n",
        "    for filename in os.listdir(folder_path):  #The for loop iterates through each file in the directory specified by folder_path.\n",
        "        if filename.endswith('.wav'):  #Checks if the file has a '.wav' extension, assuming the audio files are in WAV format.\n",
        "            file_path = os.path.join(folder_path, filename)  #Creates the full file path by joining the folder path and the filename.\n",
        "            mfccs, chroma, zero_crossing_rate, spectral_centroid = extract_features(file_path)\n",
        "            label = get_label(filename)\n",
        "            features = {\n",
        "                'feature': mfccs.mean(axis=1).tolist() + chroma.mean(axis=1).tolist() +\n",
        "                           zero_crossing_rate.mean(axis=1).tolist() + spectral_centroid.mean(axis=1).tolist(),\n",
        "                'label': label,\n",
        "            }\n",
        "            features_list.append(features)\n",
        "    return features_list\n",
        "\n",
        "def get_label(file_name):\n",
        "    if 'G - Muted' in file_name:\n",
        "        return 'g muted'\n",
        "    else:\n",
        "        return 'g correct'\n",
        "\n",
        "#Extract features and labels: Calls the extract_features function to get the audio features and calls get_label to determine the label based on the filename.\n",
        "\n",
        "#Creating a feature dictionary: Creates a dictionary features containing the concatenated mean values of different features and their corresponding label.\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/TRAINING'\n",
        "extracted_features = process_folder(folder_path)\n",
        "\n",
        "# Convert the extracted features to a DataFrame\n",
        "extracted_features_df = pd.DataFrame(extracted_features)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(extracted_features_df)\n"
      ],
      "metadata": {
        "id": "t2RQaR-62n6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ceba3d1-88bf-4636-e622-a402165f70fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               feature      label\n",
            "0    [-447.4845886230469, 73.09541320800781, 40.106...    g muted\n",
            "1    [-418.9053955078125, 52.48165512084961, 17.445...    g muted\n",
            "2    [-406.71221923828125, 62.560630798339844, -13....    g muted\n",
            "3    [-472.2129211425781, 63.41244888305664, 26.820...    g muted\n",
            "4    [-465.9186096191406, 60.71059799194336, 4.5694...    g muted\n",
            "..                                                 ...        ...\n",
            "116  [-424.48919677734375, 100.8794174194336, 24.84...  g correct\n",
            "117  [-432.6346130371094, 100.75639343261719, 25.74...  g correct\n",
            "118  [-526.615234375, 137.49990844726562, 14.868563...  g correct\n",
            "119  [-417.17724609375, 105.28143310546875, 12.7329...  g correct\n",
            "120  [-571.0491943359375, 125.1643295288086, 26.464...  g correct\n",
            "\n",
            "[121 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PHYU_cOWwr8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_features_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "prFrsRo5J8fc",
        "outputId": "5400d783-7182-45d7-cf06-6b962fa8f579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature    label\n",
              "0  [-447.4845886230469, 73.09541320800781, 40.106...  g muted\n",
              "1  [-418.9053955078125, 52.48165512084961, 17.445...  g muted\n",
              "2  [-406.71221923828125, 62.560630798339844, -13....  g muted\n",
              "3  [-472.2129211425781, 63.41244888305664, 26.820...  g muted\n",
              "4  [-465.9186096191406, 60.71059799194336, 4.5694...  g muted"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-046cc7aa-036f-48b7-a290-5ccde7dff227\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-447.4845886230469, 73.09541320800781, 40.106...</td>\n",
              "      <td>g muted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-418.9053955078125, 52.48165512084961, 17.445...</td>\n",
              "      <td>g muted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-406.71221923828125, 62.560630798339844, -13....</td>\n",
              "      <td>g muted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-472.2129211425781, 63.41244888305664, 26.820...</td>\n",
              "      <td>g muted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-465.9186096191406, 60.71059799194336, 4.5694...</td>\n",
              "      <td>g muted</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-046cc7aa-036f-48b7-a290-5ccde7dff227')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-046cc7aa-036f-48b7-a290-5ccde7dff227 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-046cc7aa-036f-48b7-a290-5ccde7dff227');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4eb83907-1382-48e5-9c9c-fea7f3dad434\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4eb83907-1382-48e5-9c9c-fea7f3dad434')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4eb83907-1382-48e5-9c9c-fea7f3dad434 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame as a CSV file\n",
        "output_csv_path = '/content/drive/MyDrive/extracted_features.csv'\n",
        "extracted_features_df.to_csv(output_csv_path, index=False)"
      ],
      "metadata": {
        "id": "XZHbEOTUW1VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "a9vxVQy0S6jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X: This variable is being used to store the features for your machine learning model. It's conventionally used to represent the input data in machine learning.\n",
        "\n",
        "#np.array(): This is creating a NumPy array, a fundamental data structure in numerical computing in Python.\n",
        "\n",
        "#extracted_features_df['feature']: This is selecting the 'feature' column from the DataFrame extracted_features_df, which contains the concatenated mean\n",
        "# values of the different audio features for each audio file.\n",
        "\n",
        "#.tolist(): This is converting the values in the 'feature' column to a Python list.\n",
        "\n",
        "#np.array(...) wraps the list in a NumPy array.\n",
        "\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['label'].tolist())   #similarly it store the labels and performs the same thing that is done by X"
      ],
      "metadata": {
        "id": "ixrYGxNAJ8oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvzHEQaCJ8rL",
        "outputId": "2a1b8712-ce5f-4585-c76b-160ed9926923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.array(pd.get_dummies(y))  #one hot encoding being applied to y, this transformation is necessary to give ml model a numerical input\n"
      ],
      "metadata": {
        "id": "spBJke32J8t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-ugqZ1eJ8wQ",
        "outputId": "56c8ca03-3df5-4e61-d921-67a946e629bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "zivyjuqmJ8yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6FZaQJQJ81I",
        "outputId": "1e60cb84-6b64-4e94-dc06-ca495aa029a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.72412659e+02,  4.24644547e+01,  1.34115915e+01, ...,\n",
              "         4.43582051e-02,  4.95182292e-02,  1.47347930e+03],\n",
              "       [-4.13487579e+02,  6.81819763e+01,  2.10493145e+01, ...,\n",
              "         6.08694479e-02,  2.55808644e-02,  1.04010459e+03],\n",
              "       [-4.02238190e+02,  1.00341560e+02,  1.90506535e+01, ...,\n",
              "         9.41649497e-01,  1.85888672e-02,  6.10115039e+02],\n",
              "       ...,\n",
              "       [-4.32634613e+02,  1.00756393e+02,  2.57437325e+01, ...,\n",
              "         8.85583997e-01,  2.33008708e-02,  6.87133785e+02],\n",
              "       [-4.05835052e+02,  7.18636475e+01,  3.77503467e+00, ...,\n",
              "         1.34404182e-01,  4.79882813e-02,  1.37562258e+03],\n",
              "       [-4.22283386e+02,  5.13687744e+01, -3.99308753e+00, ...,\n",
              "         1.45271078e-01,  3.52035030e-02,  1.26759691e+03]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9eGMut5J83S",
        "outputId": "c9a6df85-7269-4095-b742-72ec8cd41f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5Np6Kw3J85x",
        "outputId": "07d0327b-c1e5-406a-aaf6-f510e290620e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMNCQB6uJ878",
        "outputId": "6d7560fd-84f4-43d7-e0ae-fa84275d9727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VtQbfHmTVMM",
        "outputId": "a281bd3d-c354-4c34-9ac2-6e5dd96c9448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbRZYy_jTVOf",
        "outputId": "78ab71e7-7061-4b9e-b265-c4b2d8acf12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "CwqGcNioTVRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()        #Creating a Sequential model\n",
        "\n",
        "\n",
        "# First layer\n",
        "model.add(Dense(64, input_shape=(34,)))  #A dense layer with 64 neurons and an input shape of (34,), which corresponds to the number of features in your data.\n",
        "model.add(Activation('relu'))  #An activation layer using the Rectified Linear Unit (ReLU) activation function.\n",
        "model.add(Dropout(0.5))  #A dropout layer with a dropout rate of 0.5, to prevent overfitting by randomly deactivating some neurons during training\n",
        "\n",
        "# Second layer\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Third layer\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Final layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid')) #final dense layer with 1 neuron is used.\n",
        "                                          # as this is a binary classification problem, a sigmoid activation function is used, which maps the output to a\n",
        "                                          #probability between 0 and 1.\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#optimizer='adam': The Adam optimizer is used for optimizing the model's weights during training.\n",
        "#loss='binary_crossentropy': The loss function used for binary classification problems.\n",
        "#It measures the difference between the predicted outputs and the actual labels.\n",
        "#metrics=['accuracy']: During training, the model's accuracy is tracked and reported.\n",
        "\n",
        "\n",
        "\n",
        "# Reshape target labels\n",
        "y_train_reshaped = y_train[:, 0]  #This slice operation selects all rows (:) from the first column (0) of the y_train array.\n",
        "                                  # It's essentially extracting the labels from the first column.\n",
        "                                  #y_train_reshaped is now a one-dimensional array containing only the labels from the first column of y_train.\n",
        "y_test_reshaped = y_test[:, 0]\n",
        "\n",
        "\n",
        "#y_train and y_test arrays and storing them in y_train_reshaped and y_test_reshaped, respectively\n",
        "\n"
      ],
      "metadata": {
        "id": "QIfN0roQTVTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKgw_p0fTVV7",
        "outputId": "e83a0f9e-054d-4a4b-f337-7a510974f870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 64)                2240      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,625\n",
            "Trainable params: 10,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trianing my model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "num_epochs = 100\n",
        "num_batch_size = 64\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/audio_classification.hdf5',\n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train_reshaped, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test_reshaped), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQSfr1CxTVap",
        "outputId": "da566512-93bf-4406-a488-b10f69e05d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/2 [==============>...............] - ETA: 1s - loss: 74.4969 - accuracy: 0.5469\n",
            "Epoch 1: val_loss improved from inf to 5.72054, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 2s 309ms/step - loss: 88.2087 - accuracy: 0.5417 - val_loss: 5.7205 - val_accuracy: 0.8000\n",
            "Epoch 2/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 74.9384 - accuracy: 0.4219\n",
            "Epoch 2: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 80.2364 - accuracy: 0.4167 - val_loss: 8.1704 - val_accuracy: 0.8000\n",
            "Epoch 3/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 64.5658 - accuracy: 0.4375\n",
            "Epoch 3: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 72.9817 - accuracy: 0.4271 - val_loss: 9.6161 - val_accuracy: 0.8000\n",
            "Epoch 4/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 46.4712 - accuracy: 0.5469\n",
            "Epoch 4: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 43.8370 - accuracy: 0.5833 - val_loss: 10.0713 - val_accuracy: 0.8000\n",
            "Epoch 5/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 48.9043 - accuracy: 0.5938\n",
            "Epoch 5: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 49.3937 - accuracy: 0.6042 - val_loss: 9.6778 - val_accuracy: 0.8000\n",
            "Epoch 6/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 40.3649 - accuracy: 0.6250\n",
            "Epoch 6: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 45.6091 - accuracy: 0.5417 - val_loss: 9.0956 - val_accuracy: 0.8000\n",
            "Epoch 7/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 54.7005 - accuracy: 0.5000\n",
            "Epoch 7: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 54.1279 - accuracy: 0.4792 - val_loss: 8.7793 - val_accuracy: 0.8000\n",
            "Epoch 8/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 53.1618 - accuracy: 0.4844\n",
            "Epoch 8: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 64.6345 - accuracy: 0.4896 - val_loss: 8.5773 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 42.3767 - accuracy: 0.5781\n",
            "Epoch 9: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 33.3470 - accuracy: 0.6354 - val_loss: 8.1801 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 43.7589 - accuracy: 0.4688\n",
            "Epoch 10: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 42.8781 - accuracy: 0.5000 - val_loss: 7.7207 - val_accuracy: 0.8000\n",
            "Epoch 11/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 47.9571 - accuracy: 0.5312\n",
            "Epoch 11: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 38.9812 - accuracy: 0.5833 - val_loss: 7.0217 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 31.0757 - accuracy: 0.6406\n",
            "Epoch 12: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 29.0061 - accuracy: 0.6354 - val_loss: 6.3665 - val_accuracy: 0.8000\n",
            "Epoch 13/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 42.4232 - accuracy: 0.5312\n",
            "Epoch 13: val_loss did not improve from 5.72054\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 38.3314 - accuracy: 0.5625 - val_loss: 5.7682 - val_accuracy: 0.8000\n",
            "Epoch 14/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 35.9528 - accuracy: 0.5938\n",
            "Epoch 14: val_loss improved from 5.72054 to 5.19273, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 35.9430 - accuracy: 0.5938 - val_loss: 5.1927 - val_accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 36.2477 - accuracy: 0.5938\n",
            "Epoch 15: val_loss improved from 5.19273 to 4.48693, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 33.1088 - accuracy: 0.5938 - val_loss: 4.4869 - val_accuracy: 0.8000\n",
            "Epoch 16/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 28.3811 - accuracy: 0.5781\n",
            "Epoch 16: val_loss improved from 4.48693 to 3.82143, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 33.1762 - accuracy: 0.5312 - val_loss: 3.8214 - val_accuracy: 0.8000\n",
            "Epoch 17/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 28.5150 - accuracy: 0.6250\n",
            "Epoch 17: val_loss improved from 3.82143 to 3.16110, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 29.2350 - accuracy: 0.5729 - val_loss: 3.1611 - val_accuracy: 0.8000\n",
            "Epoch 18/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 23.2570 - accuracy: 0.6406\n",
            "Epoch 18: val_loss improved from 3.16110 to 2.70841, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 29.7926 - accuracy: 0.6146 - val_loss: 2.7084 - val_accuracy: 0.8000\n",
            "Epoch 19/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 24.3776 - accuracy: 0.5781\n",
            "Epoch 19: val_loss improved from 2.70841 to 2.50715, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 27.7989 - accuracy: 0.5625 - val_loss: 2.5072 - val_accuracy: 0.8000\n",
            "Epoch 20/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 23.7422 - accuracy: 0.5625\n",
            "Epoch 20: val_loss improved from 2.50715 to 2.37741, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 22.5489 - accuracy: 0.6146 - val_loss: 2.3774 - val_accuracy: 0.8000\n",
            "Epoch 21/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 26.2996 - accuracy: 0.6250\n",
            "Epoch 21: val_loss improved from 2.37741 to 2.21429, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 22.8368 - accuracy: 0.6562 - val_loss: 2.2143 - val_accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 26.4166 - accuracy: 0.6562\n",
            "Epoch 22: val_loss improved from 2.21429 to 2.01823, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 26.7417 - accuracy: 0.6250 - val_loss: 2.0182 - val_accuracy: 0.8000\n",
            "Epoch 23/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 17.5571 - accuracy: 0.6406\n",
            "Epoch 23: val_loss improved from 2.01823 to 1.87515, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 19.6868 - accuracy: 0.6458 - val_loss: 1.8751 - val_accuracy: 0.8000\n",
            "Epoch 24/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 20.7728 - accuracy: 0.5938\n",
            "Epoch 24: val_loss improved from 1.87515 to 1.72869, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 21.2363 - accuracy: 0.6042 - val_loss: 1.7287 - val_accuracy: 0.8000\n",
            "Epoch 25/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 28.3188 - accuracy: 0.4844\n",
            "Epoch 25: val_loss improved from 1.72869 to 1.58947, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 26.8832 - accuracy: 0.5000 - val_loss: 1.5895 - val_accuracy: 0.8000\n",
            "Epoch 26/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 27.1342 - accuracy: 0.5938\n",
            "Epoch 26: val_loss improved from 1.58947 to 1.46713, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 23.6972 - accuracy: 0.5729 - val_loss: 1.4671 - val_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 18.9704 - accuracy: 0.5625\n",
            "Epoch 27: val_loss improved from 1.46713 to 1.39383, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 18.6628 - accuracy: 0.5833 - val_loss: 1.3938 - val_accuracy: 0.8000\n",
            "Epoch 28/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 16.4566 - accuracy: 0.6250\n",
            "Epoch 28: val_loss improved from 1.39383 to 1.28345, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 23.0107 - accuracy: 0.5833 - val_loss: 1.2834 - val_accuracy: 0.8000\n",
            "Epoch 29/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 14.0694 - accuracy: 0.6406\n",
            "Epoch 29: val_loss improved from 1.28345 to 1.11802, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 15.2590 - accuracy: 0.6667 - val_loss: 1.1180 - val_accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 13.9970 - accuracy: 0.7344\n",
            "Epoch 30: val_loss improved from 1.11802 to 0.95038, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 12.5715 - accuracy: 0.6979 - val_loss: 0.9504 - val_accuracy: 0.8000\n",
            "Epoch 31/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 25.0916 - accuracy: 0.5000\n",
            "Epoch 31: val_loss improved from 0.95038 to 0.75648, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 25.8695 - accuracy: 0.5312 - val_loss: 0.7565 - val_accuracy: 0.8400\n",
            "Epoch 32/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 16.4409 - accuracy: 0.6406\n",
            "Epoch 32: val_loss improved from 0.75648 to 0.58734, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 21.5040 - accuracy: 0.6042 - val_loss: 0.5873 - val_accuracy: 0.8800\n",
            "Epoch 33/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 22.9310 - accuracy: 0.5312\n",
            "Epoch 33: val_loss improved from 0.58734 to 0.43836, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 20.1839 - accuracy: 0.5833 - val_loss: 0.4384 - val_accuracy: 0.8800\n",
            "Epoch 34/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 18.1685 - accuracy: 0.5938\n",
            "Epoch 34: val_loss improved from 0.43836 to 0.33354, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 16.6734 - accuracy: 0.6042 - val_loss: 0.3335 - val_accuracy: 0.9200\n",
            "Epoch 35/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 15.2697 - accuracy: 0.6406\n",
            "Epoch 35: val_loss improved from 0.33354 to 0.27451, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 17.5036 - accuracy: 0.6458 - val_loss: 0.2745 - val_accuracy: 0.9200\n",
            "Epoch 36/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 12.3158 - accuracy: 0.6719\n",
            "Epoch 36: val_loss improved from 0.27451 to 0.23963, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 11.1722 - accuracy: 0.6979 - val_loss: 0.2396 - val_accuracy: 0.9600\n",
            "Epoch 37/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 10.7837 - accuracy: 0.6719\n",
            "Epoch 37: val_loss improved from 0.23963 to 0.21492, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 12.8761 - accuracy: 0.6250 - val_loss: 0.2149 - val_accuracy: 0.9600\n",
            "Epoch 38/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 21.9600 - accuracy: 0.5469\n",
            "Epoch 38: val_loss improved from 0.21492 to 0.20006, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 20.6503 - accuracy: 0.5312 - val_loss: 0.2001 - val_accuracy: 0.9600\n",
            "Epoch 39/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 20.0365 - accuracy: 0.5469\n",
            "Epoch 39: val_loss did not improve from 0.20006\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 19.0712 - accuracy: 0.5938 - val_loss: 0.2040 - val_accuracy: 0.9200\n",
            "Epoch 40/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 14.0753 - accuracy: 0.6719\n",
            "Epoch 40: val_loss did not improve from 0.20006\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 16.4794 - accuracy: 0.6042 - val_loss: 0.2179 - val_accuracy: 0.8800\n",
            "Epoch 41/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 17.5365 - accuracy: 0.6875\n",
            "Epoch 41: val_loss did not improve from 0.20006\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 14.3740 - accuracy: 0.6875 - val_loss: 0.2281 - val_accuracy: 0.8800\n",
            "Epoch 42/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 10.1887 - accuracy: 0.7188\n",
            "Epoch 42: val_loss did not improve from 0.20006\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 9.7880 - accuracy: 0.7188 - val_loss: 0.2341 - val_accuracy: 0.8800\n",
            "Epoch 43/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 11.2979 - accuracy: 0.6406\n",
            "Epoch 43: val_loss did not improve from 0.20006\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 11.6195 - accuracy: 0.6667 - val_loss: 0.2238 - val_accuracy: 0.8800\n",
            "Epoch 44/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9982 - accuracy: 0.6562\n",
            "Epoch 44: val_loss did not improve from 0.20006\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 8.4506 - accuracy: 0.6458 - val_loss: 0.2109 - val_accuracy: 0.8800\n",
            "Epoch 45/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.1871 - accuracy: 0.6719\n",
            "Epoch 45: val_loss improved from 0.20006 to 0.19083, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 9.1103 - accuracy: 0.6875 - val_loss: 0.1908 - val_accuracy: 0.8800\n",
            "Epoch 46/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0640 - accuracy: 0.6562\n",
            "Epoch 46: val_loss improved from 0.19083 to 0.17040, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 10.6622 - accuracy: 0.6667 - val_loss: 0.1704 - val_accuracy: 0.8800\n",
            "Epoch 47/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.9529 - accuracy: 0.6719\n",
            "Epoch 47: val_loss improved from 0.17040 to 0.16909, saving model to /content/drive/MyDrive/audio_classification.hdf5\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 8.5567 - accuracy: 0.6979 - val_loss: 0.1691 - val_accuracy: 0.8800\n",
            "Epoch 48/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 10.8209 - accuracy: 0.6562\n",
            "Epoch 48: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 10.4025 - accuracy: 0.6354 - val_loss: 0.1930 - val_accuracy: 0.9200\n",
            "Epoch 49/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.9610 - accuracy: 0.6875\n",
            "Epoch 49: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 7.9226 - accuracy: 0.6562 - val_loss: 0.2234 - val_accuracy: 0.9200\n",
            "Epoch 50/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 19.3665 - accuracy: 0.5781\n",
            "Epoch 50: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 17.0995 - accuracy: 0.6042 - val_loss: 0.2621 - val_accuracy: 0.9200\n",
            "Epoch 51/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 11.0149 - accuracy: 0.6719\n",
            "Epoch 51: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 9.8963 - accuracy: 0.6771 - val_loss: 0.3184 - val_accuracy: 0.8800\n",
            "Epoch 52/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 12.2212 - accuracy: 0.5938\n",
            "Epoch 52: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 11.4968 - accuracy: 0.6042 - val_loss: 0.4134 - val_accuracy: 0.8800\n",
            "Epoch 53/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.4472 - accuracy: 0.7344\n",
            "Epoch 53: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 8.5113 - accuracy: 0.7083 - val_loss: 0.5201 - val_accuracy: 0.8800\n",
            "Epoch 54/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 12.7242 - accuracy: 0.5938\n",
            "Epoch 54: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 11.0451 - accuracy: 0.6354 - val_loss: 0.6280 - val_accuracy: 0.8400\n",
            "Epoch 55/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 11.8095 - accuracy: 0.6250\n",
            "Epoch 55: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 11.8422 - accuracy: 0.6146 - val_loss: 0.7425 - val_accuracy: 0.8400\n",
            "Epoch 56/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7626 - accuracy: 0.7188\n",
            "Epoch 56: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 8.7418 - accuracy: 0.6875 - val_loss: 0.8387 - val_accuracy: 0.8400\n",
            "Epoch 57/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 12.5551 - accuracy: 0.5625\n",
            "Epoch 57: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 12.0046 - accuracy: 0.5833 - val_loss: 0.9020 - val_accuracy: 0.8400\n",
            "Epoch 58/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6210 - accuracy: 0.7031\n",
            "Epoch 58: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 9.3407 - accuracy: 0.6562 - val_loss: 0.9420 - val_accuracy: 0.8400\n",
            "Epoch 59/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7958 - accuracy: 0.7344\n",
            "Epoch 59: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 7.7813 - accuracy: 0.7083 - val_loss: 0.9546 - val_accuracy: 0.8400\n",
            "Epoch 60/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.7948 - accuracy: 0.6562\n",
            "Epoch 60: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2598 - accuracy: 0.6667 - val_loss: 0.9296 - val_accuracy: 0.8400\n",
            "Epoch 61/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0323 - accuracy: 0.6719\n",
            "Epoch 61: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 6.5859 - accuracy: 0.6875 - val_loss: 0.8849 - val_accuracy: 0.8400\n",
            "Epoch 62/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0817 - accuracy: 0.6094\n",
            "Epoch 62: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 9.1244 - accuracy: 0.6354 - val_loss: 0.8304 - val_accuracy: 0.8400\n",
            "Epoch 63/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.0338 - accuracy: 0.7031\n",
            "Epoch 63: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 9.4230 - accuracy: 0.6667 - val_loss: 0.7944 - val_accuracy: 0.8400\n",
            "Epoch 64/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 10.3727 - accuracy: 0.6406\n",
            "Epoch 64: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 10.6327 - accuracy: 0.6146 - val_loss: 0.7434 - val_accuracy: 0.8800\n",
            "Epoch 65/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6903 - accuracy: 0.7344\n",
            "Epoch 65: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 7.3675 - accuracy: 0.6979 - val_loss: 0.7281 - val_accuracy: 0.8800\n",
            "Epoch 66/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.9685 - accuracy: 0.6875\n",
            "Epoch 66: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 8.2278 - accuracy: 0.6979 - val_loss: 0.7252 - val_accuracy: 0.8400\n",
            "Epoch 67/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.7805 - accuracy: 0.7344\n",
            "Epoch 67: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 5.6008 - accuracy: 0.6875 - val_loss: 0.7046 - val_accuracy: 0.8400\n",
            "Epoch 68/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9714 - accuracy: 0.7344\n",
            "Epoch 68: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 6.1481 - accuracy: 0.7604 - val_loss: 0.7101 - val_accuracy: 0.8400\n",
            "Epoch 69/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2359 - accuracy: 0.7656\n",
            "Epoch 69: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.5993 - accuracy: 0.7812 - val_loss: 0.7381 - val_accuracy: 0.8400\n",
            "Epoch 70/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6180 - accuracy: 0.6094\n",
            "Epoch 70: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 5.8254 - accuracy: 0.6354 - val_loss: 0.7613 - val_accuracy: 0.8400\n",
            "Epoch 71/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.5597 - accuracy: 0.6562\n",
            "Epoch 71: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 9.2777 - accuracy: 0.6667 - val_loss: 0.7840 - val_accuracy: 0.8400\n",
            "Epoch 72/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 10.6889 - accuracy: 0.5938\n",
            "Epoch 72: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 9.2335 - accuracy: 0.6458 - val_loss: 0.8069 - val_accuracy: 0.8400\n",
            "Epoch 73/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.9168 - accuracy: 0.6094\n",
            "Epoch 73: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 8.8956 - accuracy: 0.6354 - val_loss: 0.8369 - val_accuracy: 0.8400\n",
            "Epoch 74/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9781 - accuracy: 0.6719\n",
            "Epoch 74: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 8.2262 - accuracy: 0.6458 - val_loss: 0.8484 - val_accuracy: 0.8400\n",
            "Epoch 75/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0450 - accuracy: 0.6875\n",
            "Epoch 75: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 7.1054 - accuracy: 0.6667 - val_loss: 0.8506 - val_accuracy: 0.8400\n",
            "Epoch 76/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.5066 - accuracy: 0.6094\n",
            "Epoch 76: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 6.4972 - accuracy: 0.6458 - val_loss: 0.8440 - val_accuracy: 0.8400\n",
            "Epoch 77/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0011 - accuracy: 0.6719\n",
            "Epoch 77: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 6.2365 - accuracy: 0.6979 - val_loss: 0.8393 - val_accuracy: 0.8400\n",
            "Epoch 78/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.2446 - accuracy: 0.5938\n",
            "Epoch 78: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 6.5011 - accuracy: 0.6250 - val_loss: 0.8512 - val_accuracy: 0.8400\n",
            "Epoch 79/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1590 - accuracy: 0.6406\n",
            "Epoch 79: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 7.2178 - accuracy: 0.6354 - val_loss: 0.8653 - val_accuracy: 0.8400\n",
            "Epoch 80/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0452 - accuracy: 0.7188\n",
            "Epoch 80: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 6.0920 - accuracy: 0.7396 - val_loss: 0.8586 - val_accuracy: 0.8000\n",
            "Epoch 81/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.9251 - accuracy: 0.5781\n",
            "Epoch 81: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 7.1505 - accuracy: 0.6042 - val_loss: 0.8629 - val_accuracy: 0.8000\n",
            "Epoch 82/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.4217 - accuracy: 0.7656\n",
            "Epoch 82: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6826 - accuracy: 0.7917 - val_loss: 0.8726 - val_accuracy: 0.8000\n",
            "Epoch 83/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2099 - accuracy: 0.6875\n",
            "Epoch 83: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 5.1691 - accuracy: 0.6979 - val_loss: 0.8672 - val_accuracy: 0.8000\n",
            "Epoch 84/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.2889 - accuracy: 0.7656\n",
            "Epoch 84: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 5.4212 - accuracy: 0.7708 - val_loss: 0.8507 - val_accuracy: 0.8000\n",
            "Epoch 85/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3050 - accuracy: 0.6719\n",
            "Epoch 85: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 5.2125 - accuracy: 0.6979 - val_loss: 0.8413 - val_accuracy: 0.8000\n",
            "Epoch 86/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3968 - accuracy: 0.7656\n",
            "Epoch 86: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 5.4375 - accuracy: 0.7292 - val_loss: 0.8124 - val_accuracy: 0.8000\n",
            "Epoch 87/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.2700 - accuracy: 0.6875\n",
            "Epoch 87: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 5.7674 - accuracy: 0.6979 - val_loss: 0.7748 - val_accuracy: 0.8000\n",
            "Epoch 88/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3722 - accuracy: 0.8281\n",
            "Epoch 88: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.4678 - accuracy: 0.7604 - val_loss: 0.7321 - val_accuracy: 0.8000\n",
            "Epoch 89/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0037 - accuracy: 0.7031\n",
            "Epoch 89: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 5.0948 - accuracy: 0.7292 - val_loss: 0.7081 - val_accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.9333 - accuracy: 0.6562\n",
            "Epoch 90: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 5.4972 - accuracy: 0.6771 - val_loss: 0.6888 - val_accuracy: 0.8000\n",
            "Epoch 91/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.1069 - accuracy: 0.6562\n",
            "Epoch 91: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 6.2997 - accuracy: 0.6458 - val_loss: 0.6881 - val_accuracy: 0.8000\n",
            "Epoch 92/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1745 - accuracy: 0.6719\n",
            "Epoch 92: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 6.7451 - accuracy: 0.6771 - val_loss: 0.6739 - val_accuracy: 0.8000\n",
            "Epoch 93/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0474 - accuracy: 0.7500\n",
            "Epoch 93: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 6.6753 - accuracy: 0.6979 - val_loss: 0.6583 - val_accuracy: 0.8400\n",
            "Epoch 94/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.4122 - accuracy: 0.7500\n",
            "Epoch 94: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.8478 - accuracy: 0.7500 - val_loss: 0.6505 - val_accuracy: 0.8400\n",
            "Epoch 95/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.7807 - accuracy: 0.6562\n",
            "Epoch 95: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 5.2758 - accuracy: 0.6667 - val_loss: 0.6570 - val_accuracy: 0.8400\n",
            "Epoch 96/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3561 - accuracy: 0.7656\n",
            "Epoch 96: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 3.7853 - accuracy: 0.7604 - val_loss: 0.6565 - val_accuracy: 0.8400\n",
            "Epoch 97/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.7324 - accuracy: 0.5781\n",
            "Epoch 97: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 7.6708 - accuracy: 0.6250 - val_loss: 0.6496 - val_accuracy: 0.8400\n",
            "Epoch 98/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3646 - accuracy: 0.7656\n",
            "Epoch 98: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 3.2495 - accuracy: 0.7604 - val_loss: 0.6467 - val_accuracy: 0.8400\n",
            "Epoch 99/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0186 - accuracy: 0.7812\n",
            "Epoch 99: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 4.5574 - accuracy: 0.7708 - val_loss: 0.6423 - val_accuracy: 0.8400\n",
            "Epoch 100/100\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5767 - accuracy: 0.7656\n",
            "Epoch 100: val_loss did not improve from 0.16909\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 4.5814 - accuracy: 0.7396 - val_loss: 0.6410 - val_accuracy: 0.8400\n",
            "Training completed in time:  0:00:08.978220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFABP15ElVol",
        "outputId": "0e2039e2-b1fc-4753-f3ea-b95f35bf555f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('audio_classification_model.h5')\n",
        "\n",
        "print(\"Model saved.\")\n"
      ],
      "metadata": {
        "id": "71QOT_7aTVdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ecd94a-d954-4733-b727-2b1f695ad514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model('/content/audio_classification_model.h5')\n",
        "\n",
        "# Now you can use loaded_model for predictions or further training\n"
      ],
      "metadata": {
        "id": "OyfZe5AETVfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a function named 'features_extractor' that returns a tuple of features.\n",
        "# You can replace 'features_extractor' with your actual function name.\n",
        "\n",
        "# Provide the path to the audio file you want to predict\n",
        "filename = \"/content/drive/MyDrive/TEST/G - Muted 2.wav\"\n",
        "\n",
        "# Extract features from the audio file using the 'features_extractor' function\n",
        "mfccs, chroma, zero_crossing_rate, spectral_centroid = extract_features(filename)\n",
        "\n",
        "# Concatenate the extracted features\n",
        "prediction_feature = np.concatenate((mfccs.mean(axis=1), chroma.mean(axis=1),\n",
        "                                     zero_crossing_rate.mean(axis=1), spectral_centroid.mean(axis=1)))\n",
        "\n",
        "# Reshape the input features to match the model's input shape\n",
        "prediction_feature = prediction_feature.reshape(1, -1)  # Reshape to (1, number_of_features)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "predicted_probabilities = model.predict(prediction_feature)\n",
        "predicted_class = int(predicted_probabilities > 0.5)  # Assuming threshold of 0.5\n",
        "\n",
        "# Map the predicted class back to the label\n",
        "predicted_label = 'g muted' if predicted_class == 0 else 'g correct'\n",
        "\n",
        "print(\"Predicted Label:\", predicted_label)\n",
        "print(\"Predicted Probabilities:\", predicted_probabilities)\n"
      ],
      "metadata": {
        "id": "1sigDdDWTVnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71328270-aa31-46ee-84f6-39dce3ed9881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n",
            "Predicted Label: g muted\n",
            "Predicted Probabilities: [[4.9236304e-14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Assuming you have your trained model 'model' and test data 'X_test' and 'y_test_reshaped'\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test_reshaped, y_pred)\n",
        "\n",
        "# Define class labels\n",
        "class_labels = ['g muted', 'g correct']\n",
        "\n",
        "# Create a confusion matrix plot\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='.0f')\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "UlrYcirXoLie",
        "outputId": "3ba6a72b-c237-41ec-dc4b-083f6188c1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omHOPRpVwu9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ts2a_Sldwu_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFwaMQ1rwvBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iWmFNMiOwvEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NX1B4_16wvHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ce1PjHktwvJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3e-FgREwvM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}